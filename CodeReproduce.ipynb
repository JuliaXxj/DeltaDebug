{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df4fb33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/nhamlv-55/CFI_NNs/blob/master/MNIST_toy/Experiment-Feb28-xujie-Copy1.ipynb\n",
    "\n",
    "from models import FeedforwardNeuralNetModel, TinyCNN, PatternClassifier, NewTinyCNN\n",
    "import regularizer_losts as rl\n",
    "from torchvision import datasets, transforms\n",
    "from torch import optim\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import utils as CFI_utils\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "#from frozendict import frozendict\n",
    "from datetime import datetime\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "colors = sns.color_palette(\"tab10\")\n",
    "\n",
    "#Logging stuffs\n",
    "import logging\n",
    "import sys\n",
    "# Create logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create STDERR handler\n",
    "handler = logging.StreamHandler(sys.stderr)\n",
    "# ch.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create formatter and add it to the handler\n",
    "formatter = logging.Formatter('%(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Set STDERR handler as the only handler \n",
    "logger.handlers = [handler]\n",
    "\n",
    "#configs\n",
    "epochs = 10\n",
    "batch_size = 1000\n",
    "test_batch_size = 10000\n",
    "stable_batch_size = 60000\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)\n",
    "\n",
    "lr = 0.01\n",
    "log_interval = 100\n",
    "\n",
    "#torch specific configs\n",
    "torch.manual_seed(1)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "train_kwargs = {'batch_size': batch_size}\n",
    "\n",
    "test_kwargs = {'batch_size': test_batch_size}\n",
    "stable_kwargs = {'batch_size': stable_batch_size}\n",
    "\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "                   'pin_memory': True,\n",
    "                   'shuffle': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "    stable_kwargs.update(cuda_kwargs)\n",
    "class Shift:\n",
    "    def __init__(self, shift = 0):\n",
    "        print(\"alive\")\n",
    "        self.shift = shift\n",
    "\n",
    "    def __call__(self, arr):\n",
    "        print(\"running\")\n",
    "        #print(arr)\n",
    "        return arr\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}()\"\n",
    "    \n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "\n",
    "        # h and w are swapped for landmarks because for images,\n",
    "        # x and y axes are axis 1 and 0 respectively\n",
    "        landmarks = landmarks * [new_w / w, new_h / h]\n",
    "\n",
    "        return {'image': img, 'landmarks': landmarks}\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "   \n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "   \n",
    "  \n",
    "])\n",
    "\n",
    "def shift_and_roll(arr : torch.Tensor, x : int , y : int) -> torch.Tensor:\n",
    "    return torch.roll(arr, shifts = (x,y), dims = (0,1)) #indexing\n",
    "def shift(arr : torch.Tensor, x : int , y : int) -> torch.Tensor:\n",
    "\n",
    "    pad = [0,0,0,0]\n",
    "    x_start = 0\n",
    "    x_end = 0\n",
    "    y_start = 0\n",
    "    y_end = 0\n",
    "    if x >= 0:\n",
    "        pad[0] = x\n",
    "        x_start = 0\n",
    "        x_end = 28\n",
    "    else:\n",
    "        pad[1] = abs(x)\n",
    "        x_start = -28\n",
    "         \n",
    "         \n",
    "        \n",
    "         \n",
    "    \n",
    "    if y >= 0:\n",
    "        pad[2] = y\n",
    "        y_start = 0\n",
    "        y_end = 28\n",
    "    else:\n",
    "        pad[3] = abs(y)\n",
    "        y_start= -28\n",
    "        print(\"ys is {}\".format(y_start))\n",
    "    \n",
    "\n",
    "    padder = torch.nn.ZeroPad2d(tuple(pad))\n",
    "  \n",
    "    result = padder(arr)\n",
    "\n",
    "    if y < 0:\n",
    "        y_end = result.shape[0]\n",
    "    if x < 0:\n",
    "        x_end = result.shape[1]\n",
    "    \n",
    "    return result[y_start:y_end, x_start:x_end]\n",
    "\n",
    "def noisify(arr : torch.Tensor , distribution : torch.distributions.Distribution) -> torch.Tensor: #randomly add noise\n",
    "   \n",
    "    #print(distribution.sample(arr.size()).shape\\\\)\n",
    "    #print(torch.reshape(distribution.sample(arr.size()), (28,28)).shape)\n",
    "   \n",
    "    noise = torch.reshape(distribution.sample(arr.size()), (arr.shape))\n",
    "    return arr + noise\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "   \n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55a02c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataset(dataset):\n",
    "    '''\n",
    "    DO A STATE CHANGE\n",
    "    '''\n",
    "    shift_x = 1\n",
    "    shift_y = 0\n",
    "    mu = 1\n",
    "    sigma = 1\n",
    "    do_shift = False\n",
    "    do_noisfy = True\n",
    "    modification_string = \"base\"\n",
    "    if do_shift:\n",
    "        modification_string += \" -shift {} {} - \".format(shift_x, shift_y)\n",
    "    if do_noisfy:\n",
    "        modification_string += \" -noise added using gaussian using mean {} and stddev {}- \".format(mu, sigma)\n",
    "    for i in range(dataset.data.shape[0]):\n",
    "        if do_shift:\n",
    "            dataset.data[i,:,:] = shift(dataset.data[i,:,:],shift_x, shift_y)\n",
    "        \n",
    "        if do_noisfy:\n",
    "            gaussian = torch.distributions.Normal(loc = mu, scale = sigma)# loc = mu, scale = stddev\n",
    "\n",
    "            dataset.data[i,:,:] = noisify(dataset.data[i,:,:], gaussian)\n",
    "    return modification_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e0c455",
   "metadata": {},
   "source": [
    "## Train/Load model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26794122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                            | 0/10 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 216. MiB for an array with shape (1536, 64, 24, 24) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 48>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(data\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m     69\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(output, target)\n\u001b[1;32m---> 70\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     72\u001b[0m CFI_utils\u001b[38;5;241m.\u001b[39mtest(model, device, test_loader)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venvpy39\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venvpy39\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\XXJ-PersonalStuff\\Grad CS\\Research\\DeltaDebug\\models.py:60\u001b[0m, in \u001b[0;36mget_gradient.<locals>.hook\u001b[1;34m(model, grad_input, grad_output)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(raw) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     59\u001b[0m raw \u001b[38;5;241m=\u001b[39m raw[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m---> 60\u001b[0m gradient_logger[name] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradient_logger\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m gradient_logger \u001b[38;5;28;01melse\u001b[39;00m raw\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 216. MiB for an array with shape (1536, 64, 24, 24) and data type float32"
     ]
    }
   ],
   "source": [
    "def check_gradient(grad, label, last_sorted_grads, plot = False):\n",
    "    logging.info(\"CHECKING GRADIENT FOR LABEL {}\".format(label))\n",
    "    sum_abs_grad = np.sum(abs(grad[label]), axis = 0)\n",
    "    \n",
    "    current_sorted_grad = (-sum_abs_grad).argsort()\n",
    "    \n",
    "#     if len(last_sorted_grads[label]) > 0:\n",
    "#         for k in [100, 200, 300, 400]:\n",
    "#             prev_top_k = set(last_sorted_grads[label][-1][:k])\n",
    "#             current_top_k = set(current_sorted_grad[:k])\n",
    "#             intersect = prev_top_k.intersection(current_top_k)\n",
    "#             logging.info('k = {}. How many top Gradients are stable since last epoch?: {}'.format(k, len(intersect)))\n",
    "        \n",
    "    for k in [0, 9, 99, 199]:    \n",
    "        logging.debug('{}th biggest gradient = {}'.format(k, np.sort(-sum_abs_grad)[k]))\n",
    "    if plot:\n",
    "        fig = plt.figure(figsize=(30, 1))\n",
    "        plt.bar(range(sum_abs_grad.shape[0]), sum_abs_grad)\n",
    "        plt.show()\n",
    "        print(sum_abs_grad.max(), sum_abs_grad.argmax(), sum_abs_grad.min())\n",
    "\n",
    "    return current_sorted_grad\n",
    "\n",
    "\n",
    "\n",
    "#init stuffs\n",
    "LOAD = False\n",
    "# LOADPATH = 'FFN19-17-24'\n",
    "LOADPATH = 'FFN18_28_21'\n",
    "\n",
    "LAST_N_EPOCHS = 10\n",
    "\n",
    "dataset1 = datasets.MNIST('./data', train=True, download=False,\n",
    "                          transform=transform)\n",
    "dataset2 = datasets.MNIST('./data', train=False, download=False,\n",
    "                          transform=transform)\n",
    "\n",
    "\n",
    "#transform_dataset(dataset1)\n",
    "#modification_string = transform_dataset(dataset2)\n",
    "modification_string = \"\"\n",
    "train_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "# model = FeedforwardNeuralNetModel(28*28, 128, 10).to(device)\n",
    "model = NewTinyCNN().to(device)\n",
    "\n",
    "if LOAD:\n",
    "    model.load_state_dict(torch.load(LOADPATH))\n",
    "else:\n",
    "\n",
    "    epochs = 10\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma = 0.7)\n",
    "    last_sorted_grads = defaultdict(list)\n",
    "    \n",
    "    all_rows = []\n",
    "    \n",
    "    for epoch in tqdm(range(1, epochs + 1)):\n",
    "        model.register_gradient()\n",
    "        model.train()\n",
    "        target_log  = None # need to record the label to match with the gradient later\n",
    "        for data, target in train_loader:\n",
    "            target_log = np.concatenate((target_log, target), axis = 0) if target_log is not None else target\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data.float())\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        CFI_utils.test(model, device, test_loader)\n",
    "#         scheduler.step()\n",
    "        grad = CFI_utils.get_grad_each_label(model.gradient_log, \n",
    "                                      target_log = target_log, \n",
    "                                      layers = ['fc1', 'fc2', 'fc3', 'fc4'], \n",
    "#                                       layers = ['conv1', 'conv2','fc1', 'fc2'],\n",
    "                                      labels = range(10))\n",
    "        torch.save(model.state_dict(), model.model_savename())\n",
    "        \n",
    "        row_data = []\n",
    "        for label in range(10):\n",
    "            r = []\n",
    "            logging.info(\"After {} epoch:\".format(epoch))\n",
    "            last_sorted_grads[label].append(check_gradient(grad, label, last_sorted_grads))\n",
    "            \n",
    "            \n",
    "            if epoch >= LAST_N_EPOCHS:\n",
    "                for k in [100, 200, 300, 400]:\n",
    "                    all_top_k = [set(sorted_grad[:k]) for sorted_grad in last_sorted_grads[label][-LAST_N_EPOCHS:]]\n",
    "                    intersect = set.intersection(*all_top_k)\n",
    "                    logging.info('k = {}. How many top Gradients are stable among all last {} epochs?: {}'.format(k, LAST_N_EPOCHS, len(intersect)))\n",
    "\n",
    "                    \n",
    "\n",
    "with torch.no_grad():\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for data, target in dataset2:\n",
    "#         if int(torch.argmax(model.cpu()(data.cpu()), dim = 1)) == target:\n",
    "        if int(torch.argmax(model.cuda()(data.cuda()), dim = 1)) == target:\n",
    "            correct += 1\n",
    "        total+=1\n",
    "    \"accuracy {}\".format( correct/total)\n",
    "    modification_string += \" -accuracy {}-\".format( correct/total)\n",
    "    print(modification_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a07020c",
   "metadata": {},
   "source": [
    "#### Compute all patterns in the training set, and put them into corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a5d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patterns:\n",
    "    def __init__(self, model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, labels, layers):\n",
    "        self._model = model\n",
    "        self.label2patterns = {}\n",
    "        self.label2idx = {}\n",
    "        self._labels = labels\n",
    "        self._layers = layers\n",
    "        self._dataloader = dataloader\n",
    "        self._populate()\n",
    "        \n",
    "    def _populate(self):\n",
    "        \n",
    "        label2patterns = {}\n",
    "        label2idx = {}\n",
    "        for label in self._labels:\n",
    "            patterns = []\n",
    "            filter_ids = []\n",
    "            \n",
    "            for data, target in self._dataloader:\n",
    "                \n",
    "                flter = np.where(target == label)\n",
    "                filter_ids.append(flter)\n",
    "                data = data[flter]\n",
    "                logging.debug(data.shape[0])\n",
    "                pattern = self._model.get_pattern(data, layers, device, flatten = True)\n",
    "                logging.debug(pattern.shape)\n",
    "                patterns.append(pattern)\n",
    "\n",
    "            patterns = np.squeeze(np.concatenate(patterns, axis = 0))\n",
    "            filter_ids = np.squeeze(np.concatenate(filter_ids, axis = 0))\n",
    "            label2patterns[label] = patterns\n",
    "            label2idx[label] = filter_ids\n",
    "            \n",
    "            logging.info(patterns.shape)\n",
    "        \n",
    "        #freeze\n",
    "        self.label2patterns = dict(label2patterns)\n",
    "        self.label2idx = dict(label2idx)\n",
    "        \n",
    "    def apply_filter(self, f):\n",
    "        pass\n",
    "    \n",
    "    def unique():\n",
    "        pass\n",
    "    \n",
    "    def query_pattern():\n",
    "        pass\n",
    "    \n",
    "    \n",
    "\n",
    "layers = ['fc1', 'fc2', 'fc3', 'fc4']\n",
    "# layers = ['conv1', 'conv2','fc1', 'fc2']\n",
    "\n",
    "labels = range(10)\n",
    "K = 25\n",
    "stable_loader = torch.utils.data.DataLoader(dataset1, **stable_kwargs)\n",
    "\n",
    "all_patterns = Patterns(model = model,\n",
    "                        dataloader = stable_loader,\n",
    "                        labels = labels,\n",
    "                        layers = layers)\n",
    "all_test_patterns = Patterns(model = model,\n",
    "                        dataloader = test_loader,\n",
    "                        labels = labels,\n",
    "                        layers = layers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b5b3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can only study gradient if the model is trained\n",
    "# FIXME: should save gradient into a pickle as well\n",
    "if not LOAD:\n",
    "    for K in [25, 50, 100]:\n",
    "        print(\"K=\", K)\n",
    "        row = []\n",
    "        row.append(str(K))\n",
    "        for label in labels:\n",
    "            #construct the stable gradients \n",
    "            all_top_k = [set(sorted_grad[:K]) for sorted_grad in last_sorted_grads[label][-LAST_N_EPOCHS:]]\n",
    "            intersect = set.intersection(*all_top_k)\n",
    "            stable_grad = np.array(sorted(list(intersect)))\n",
    "            print(\"There are {} stable grad in top K\".format(len(stable_grad)))\n",
    "            print(stable_grad)\n",
    "\n",
    "            logging.info(all_patterns[label].shape)\n",
    "            print(\"LABEL:\", label)\n",
    "            print(\"how many unique paths in the full pattern?\", np.unique(all_patterns[label], axis = 0).shape)\n",
    "            print(\"how many unique paths in the filtered pattern?\", np.unique(all_patterns[label][:, stable_grad ], axis = 0).shape)\n",
    "            print(\"how many unique paths in the randomly filtered pattern?\", \n",
    "                  np.unique(patterns[:, \n",
    "                                     np.random.choice(458, len(stable_grad), replace = False) ], axis = 0).shape)\n",
    "            row.append(\"|\".join([str(len(stable_grad)),\n",
    "                                 str(np.unique(all_patterns[label], axis = 0).shape[0]),\n",
    "                                 str(np.unique(all_patterns[label][:, stable_grad ], axis = 0).shape[0]),\n",
    "                                 str(np.unique(all_patterns[label][:, np.random.choice(458, len(stable_grad), replace = False) ], axis = 0).shape[0])\n",
    "                                ]))\n",
    "        all_rows.append(\",\".join(row)+\"\\n\")\n",
    "\n",
    "    with open(\"gradient_exp_log_2.csv\", \"w\") as f:\n",
    "        f.write(\"K,\"+\",\".join([str(l) for l in labels]) + \"\\n\")\n",
    "        f.writelines(all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6217154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.bool_):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "    \n",
    "\n",
    "\n",
    "all_stable_relus = []\n",
    "\n",
    "all_alpha_patterns = {\"model\": LOADPATH}\n",
    "\n",
    "write_log = True\n",
    "if write_log:\n",
    "    ReLU_exp_log = open(\"relu_exp_log{}.csv\".format(datetime.now().strftime(\"%H-%M-%S\")), \"w\")\n",
    "    ReLU_exp_json = open(\"relu_exp_data{}.json\".format(datetime.now().strftime(\"%H-%M-%S\")), \"w\")\n",
    "    ReLU_exp_log.write(\"Epsilon,Label,NumStableReLU,NumUniqueAP,Alpha Pattern Cover\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# for epsilon in [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05]:\n",
    "epsilon_to_patterns = dict()\n",
    "for epsilon in [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05]:\n",
    "    alpha_patterns = {}\n",
    "    label_to_most_common_pattern = dict()\n",
    "    for label in all_patterns.label2patterns:\n",
    "#     for label in [0,2,8]:\n",
    "        patterns = all_patterns.label2patterns[label]\n",
    "        print(patterns.shape)\n",
    "\n",
    "        occuring_patterns = patterns.tolist() #make patterns into list of lists first dim is each example, second dim is the pattern\n",
    "        most_common_pattern = max(occuring_patterns, key =  lambda x :occuring_patterns.count(x)) #argmax the count of each pattern\n",
    "\n",
    "        #print(\"most common pattern: {}\".format(most_common_pattern) )\n",
    "        \n",
    "        pattern_indices = list(filter( lambda x : most_common_pattern[x] , range(len(most_common_pattern))   ))#get true indices     \n",
    "        #print(\"pattern_indices: {}\".format(pattern_indices))\n",
    "        label_to_most_common_pattern[label] = (pattern_indices,most_common_pattern)\n",
    "        relu_sum = np.sum(patterns, axis = 0).squeeze()\n",
    "        \n",
    "        print(\"threshold: \", epsilon*patterns.shape[0], (1-epsilon)*patterns.shape[0])\n",
    "        \n",
    "#         print(\"relu_sum, layer-1 \", relu_sum[:256])\n",
    "#         print(\"relu_sum, layer-2 \", relu_sum[256:384])\n",
    "#         print(\"relu_sum, layer-3 \", relu_sum[384:448])\n",
    "        print(\"relu_sum, prediction\", relu_sum[448:458])\n",
    "#         print(\"relu_sum\", relu_sum[-10:])\n",
    "        \n",
    "        non_active_neurons = np.where(relu_sum<=epsilon*patterns.shape[0])\n",
    "        active_neurons = np.where(relu_sum>=(1-epsilon)*patterns.shape[0])\n",
    "        print(\"non active neurons: \", non_active_neurons)\n",
    "        print(\"active neurons: \", active_neurons)\n",
    "\n",
    "        stable_idx = np.concatenate([np.where(relu_sum<=epsilon*patterns.shape[0]), \n",
    "                                     np.where(relu_sum>=(1-epsilon)*patterns.shape[0])],\n",
    "                                    axis = 1\n",
    "                                    ).squeeze()\n",
    "        neuro_idx = patterns.shape[1] - 10 + label\n",
    "        if neuro_idx not in stable_idx:\n",
    "            print(f\"WARN: neuro_idx = {neuro_idx} for label {label} is not stable, let's include it anyway\")\n",
    "            stable_idx = np.append(stable_idx, neuro_idx)\n",
    "        stable_idx = sorted(stable_idx) #sort the indices of the stable ReLUs. \n",
    "        unique_patterns, freq = np.unique(patterns[:, stable_idx ], axis = 0, return_counts=True)\n",
    "        alpha_p = unique_patterns[np.argmax(freq)]\n",
    "        print()\n",
    "        print(\"Label is \", label)\n",
    "        print(\"Stable ReLUs\", stable_idx)\n",
    "        print(\"how many unique paths in the filtered pattern?\", unique_patterns.shape)\n",
    "        print(\"their freq\\n\", freq, freq.shape)\n",
    "#         print(\"most prominent pattern\", np.argmax(freq), alpha_p)\n",
    "#         print(\"alpha_p is \", alpha_p)\n",
    "\n",
    "\n",
    "        assert(len(stable_idx) == alpha_p.shape[-1])\n",
    "        assert(freq.shape[0]==unique_patterns.shape[0])\n",
    "#         alpha_patterns[label] = (stable_idx, tuple(alpha_p))\n",
    "#         alpha_patterns[label] = {\"stable_idx\": stable_idx,\n",
    "#                                 \"alpha_pattern\": alpha_p,\n",
    "#                                 \"alpha_pattern_coverage\": freq.max()/freq.sum(),\n",
    "#                                 \"pattern_frequency\": freq}\n",
    "        alpha_patterns[label] = {\"stable_idx\": stable_idx,\n",
    "                                 \"active_neurons\": active_neurons[0],\n",
    "                                 \"non_active_neurons\": non_active_neurons[0],\n",
    "                                \"alpha_pattern\": alpha_p,\n",
    "                                \"alpha_pattern_coverage\": freq.max()/freq.sum(),\n",
    "                                \"pattern_frequency\": freq}\n",
    "    \n",
    "#         print(\"pattern frequency:\", freq)\n",
    "        print(\"primary pattern coverage: \", freq.max()/freq.sum(),)\n",
    "\n",
    "        if write_log:\n",
    "            ReLU_exp_log.write(\"{},{},{},{},{}\\n\".format(epsilon, label, len(stable_idx), unique_patterns.shape[0], freq.max()/freq.sum()))\n",
    "    all_alpha_patterns[epsilon] = alpha_patterns\n",
    "    epsilon_to_patterns[epsilon] = label_to_most_common_pattern\n",
    "json.dump(epsilon_to_patterns, open(\"most_common_patterns{}.json\".format(datetime.now().strftime(\"%H-%M-%S\")), \"w\")) \n",
    "    \n",
    "if write_log:\n",
    "    ReLU_exp_log.close()\n",
    "    json.dump(all_alpha_patterns, fp = ReLU_exp_json, indent=2, cls=NpEncoder)\n",
    "    ReLU_exp_json.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f37b9",
   "metadata": {},
   "source": [
    "## Apply delta debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a095ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from custom_transform import *\n",
    "from models import MNISTNet\n",
    "from transforms import TRANSFORMS\n",
    "from mask import *\n",
    "import imageio\n",
    "from utils import generate_gif\n",
    "import os\n",
    "\n",
    "# For delta debugging\n",
    "img_eraser = CustomizeMask(value=0)\n",
    "\n",
    "# Parameters\n",
    "THRESHOLD = 0.6\n",
    "ROOT_FOLDER = \"./\"\n",
    "TMP_IMG_FOLDER = os.path.join(ROOT_FOLDER, \"mnistact_gif_img\")\n",
    "\n",
    "RESULT_FOLDER_NAME = \"result_samples_mnistact\"\n",
    "GIF_RESULT = ROOT_FOLDER + RESULT_FOLDER_NAME + \"/{}/gif_results/img_{}.gif\"\n",
    "IMG_RESULT = ROOT_FOLDER + RESULT_FOLDER_NAME + \"/{}/img_results/img_{}.png\"\n",
    "\n",
    "# Create folders for save all the results, only run once\n",
    "create_folders = False\n",
    "if create_folders:\n",
    "    os.mkdir(ROOT_FOLDER + RESULT_FOLDER_NAME)\n",
    "    for i in range(10):\n",
    "        os.mkdir(ROOT_FOLDER+RESULT_FOLDER_NAME+\"/{}/\".format(i))\n",
    "        os.mkdir(ROOT_FOLDER+RESULT_FOLDER_NAME+\"/{}/{}\".format(i,'gif_results'))\n",
    "        os.mkdir(ROOT_FOLDER+RESULT_FOLDER_NAME+\"/{}/{}\".format(i,'img_results'))\n",
    "# MODEL_PATH = \"./cifar10_net_v2.pth\"\n",
    "\n",
    "epsilon_for_pattern = 0.05\n",
    "\n",
    "# We have loaded the dataset already at the beginning\n",
    "\n",
    "def check_activation(data, label, device, active_neurons_idx, non_active_neurons_idx):\n",
    "    \n",
    "    img_pattern = model.get_pattern(data, layers, device, flatten = True)\n",
    "    img_non_active_neurons = img_pattern[:, non_active_neurons_idx]\n",
    "    img_active_neurons = img_pattern[:, active_neurons_idx]\n",
    "\n",
    "    \n",
    "    return img_non_active_neurons.sum() == len(non_active_neurons_idx) and img_active_neurons.sum() == len(active_neurons_idx)\n",
    "\n",
    "\n",
    "def delta_debugging_general_new(img_eraser, model, threshold, img, label):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    active_neurons_idx = all_alpha_patterns[epsilon_for_pattern][label][\"active_neurons\"]\n",
    "    non_active_neurons_idx = all_alpha_patterns[epsilon_for_pattern][label][\"non_active_neurons\"]\n",
    "\n",
    "    \n",
    "    c, h, w = img.shape\n",
    "\n",
    "    current_unmasked_pixels = torch.ones((c, h, w))\n",
    "    \n",
    "    keep_going = True\n",
    "    smaller_chunk = True\n",
    "\n",
    "    current_img = img.clone()\n",
    "    current_pred = None\n",
    "    current_pred_prob = 1\n",
    "\n",
    "    prev_img = img.clone()\n",
    "    prev_pred = None\n",
    "    prev_pred_prob = 1\n",
    "    \n",
    "\n",
    "    img_counter = 0\n",
    "    img_names = []\n",
    "    smaller_group_number = None  \n",
    "#     img_folder = \"./gif_img\"\n",
    "    if not os.path.exists(TMP_IMG_FOLDER):\n",
    "        os.mkdir(TMP_IMG_FOLDER)\n",
    "    if smaller_chunk:\n",
    "        smaller_group_number = 2\n",
    "#         for _ in range(1):\n",
    "\n",
    "        while keep_going:\n",
    "            print(\"partition: \", smaller_group_number)\n",
    "            prev_img, prev_pred, prev_pred_prob = current_img, current_pred, current_pred_prob\n",
    "            \n",
    "            # save figures for gif\n",
    "            \n",
    "            figure = plt.figure()\n",
    "            plt.title(\"Pred prob: {}\".format(prev_pred_prob))\n",
    "            plt.imshow(prev_img.reshape(28, 28), cmap=\"gray\")\n",
    "            img_name = '{}.png'.format(img_counter)\n",
    "            plt.savefig(os.path.join(TMP_IMG_FOLDER, img_name))\n",
    "            plt.close(figure)\n",
    "            img_names.append(img_name)\n",
    "            img_counter += 1\n",
    "\n",
    "            pixel_left = int(torch.sum(current_unmasked_pixels).item())\n",
    "            if smaller_group_number > pixel_left:\n",
    "                smaller_group_number = pixel_left\n",
    "            \n",
    "            try:\n",
    "                all_new_masks = split_in_smaller_groups(current_unmasked_pixels, smaller_group_number)\n",
    "            except:\n",
    "                keep_going = False\n",
    "                continue\n",
    "                \n",
    "            best_group_num = None\n",
    "            best_pred_prob = 0\n",
    "            for m_idx in range(smaller_group_number):\n",
    "                new_unmask = all_new_masks[m_idx]\n",
    "                new_img = img_eraser(img, new_unmask)\n",
    "                new_extend_img = new_img[None, :]\n",
    "                with torch.no_grad():\n",
    "                    output = model(new_extend_img.to(device))\n",
    "                    # TODO: check image pattern\n",
    "                    same_activation = check_activation(new_extend_img, label, device, active_neurons_idx, non_active_neurons_idx)\n",
    "                    if same_activation:\n",
    "                        print(same_activation)\n",
    "                new_pred_prob = torch.max(torch.exp(output)).item()\n",
    "                new_pred = torch.argmax(output).item()\n",
    "                if new_pred_prob > threshold and new_pred == label and new_pred_prob > best_pred_prob and same_activation:\n",
    "                    current_unmasked_pixels = new_unmask\n",
    "                    current_img, current_pred, current_pred_prob = new_img, new_pred, new_pred_prob\n",
    "                    best_group_num = m_idx\n",
    "\n",
    "            if best_group_num is None:\n",
    "                if smaller_group_number == pixel_left:\n",
    "                    keep_going = False\n",
    "                else:\n",
    "                    smaller_group_number += 1\n",
    "                \n",
    "    print(\"in the end:\", smaller_group_number)\n",
    "    generate_gif(GIF_RESULT.format(label, img_idx), TMP_IMG_FOLDER, img_names, True)\n",
    "    return prev_img , prev_pred, prev_pred_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f7f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_idx in range(2, 3):\n",
    "    (img, label) = torch.utils.data.Subset(dataset2, [img_idx])[0]\n",
    "#     if label != 8:\n",
    "#         continue\n",
    "#     plt.figure()\n",
    "#     plt.imshow(img.reshape(28, 28), cmap=\"gray\")\n",
    "\n",
    "    pred_img, pred_class, pred_prob = delta_debugging_general_new(img_eraser, model, 0.6, img, label)\n",
    "# #     plt.figure()\n",
    "# #     plt.imshow(pred_img.reshape(28, 28), cmap=\"gray\")\n",
    "\n",
    "#     figure = plt.figure()\n",
    "#     f, axarr = plt.subplots(1,2)\n",
    "#     axarr[0].imshow(img.reshape(28, 28), cmap=\"gray\")\n",
    "#     axarr[1].imshow(pred_img.reshape(28, 28), cmap=\"gray\")\n",
    "#     plt.title(\"Final pred prob: {}\".format(pred_prob))\n",
    "#     plt.savefig(\"./result_samples/{}/img_results/img_{}.png\".format(label, img_idx))\n",
    "#     plt.close(figure)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a28454b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
