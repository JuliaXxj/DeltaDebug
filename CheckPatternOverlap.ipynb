{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5970fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method \n",
    "from cleverhans.torch.attacks.projected_gradient_descent import projected_gradient_descent\n",
    "from cleverhans.torch.attacks.noise import noise \n",
    "from cleverhans.torch.attacks.hop_skip_jump_attack import hop_skip_jump_attack \n",
    "from cleverhans.torch.attacks.spsa import spsa \n",
    "from cleverhans.torch.attacks.carlini_wagner_l2 import carlini_wagner_l2 \n",
    "from cleverhans.torch.attacks.sparse_l1_descent import sparse_l1_descent \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb7feb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "import regularizer_losts as rl\n",
    "from torchvision import datasets, transforms\n",
    "from torch import optim\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import utils as CFI_utils\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from absl import app, flags\n",
    "from easydict import EasyDict\n",
    "import torch.nn as nn\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from custom_transform import *\n",
    "from transforms import TRANSFORMS\n",
    "from mask import *\n",
    "import imageio\n",
    "from utils import generate_gif\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aacfefba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "   \n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "   \n",
    "  \n",
    "])\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 1000\n",
    "test_batch_size = 10000\n",
    "stable_batch_size = 60000\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)\n",
    "\n",
    "#torch specific configs\n",
    "torch.manual_seed(1)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "train_kwargs = {'batch_size': batch_size}\n",
    "\n",
    "test_kwargs = {'batch_size': test_batch_size}\n",
    "stable_kwargs = {'batch_size': stable_batch_size}\n",
    "\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "                   'pin_memory': True,\n",
    "                   'shuffle': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "    stable_kwargs.update(cuda_kwargs)\n",
    "    \n",
    "    \n",
    "#init stuffs\n",
    "\n",
    "LOADPATH = 'FFN18_28_21'\n",
    "\n",
    "LAST_N_EPOCHS = 10\n",
    "\n",
    "dataset1 = datasets.MNIST('./data', train=True, download=False,\n",
    "                          transform=transform)\n",
    "dataset2 = datasets.MNIST('./data', train=False, download=False,\n",
    "                          transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "modification_string = \"\"\n",
    "train_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "model = FeedforwardNeuralNetModel(28*28, 128, 10).to(device)\n",
    "model.load_state_dict(torch.load(LOADPATH, map_location=device))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914d86fb",
   "metadata": {},
   "source": [
    "## Check pattern overlap ratio between random two images. The pattern here includes all the neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "056f6ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average pattern overlap ratio over 200 random pairs 0.8023908296943236\n"
     ]
    }
   ],
   "source": [
    "layers = ['fc1', 'fc2', 'fc3', 'fc4']\n",
    "\n",
    "# Check average overlap ratio on 200 random pairs\n",
    "pair_num = 200\n",
    "\n",
    "list1 = np.random.choice(range(10000), pair_num, replace=False)\n",
    "list2 = np.random.choice(range(10000), pair_num, replace=False)\n",
    "\n",
    "avg_pair_check_ratio = 0\n",
    "\n",
    "for idx1, idx2 in zip(list1, list2):\n",
    "    pair_imgs = torch.utils.data.Subset(dataset2, [idx1, idx2])\n",
    "    (pair_img1, pair_target1) = pair_imgs[0]\n",
    "    (pair_img2, pair_target2) = pair_imgs[1]\n",
    "    \n",
    "    pair_img1_extend = pair_img1[None, :]\n",
    "    pair_img2_extend = pair_img2[None, :]\n",
    "    \n",
    "    pair_img1_pattern = model.get_pattern(pair_img1_extend, layers, device, flatten=True)\n",
    "    pair_img2_pattern = model.get_pattern(pair_img2_extend, layers, device, flatten=True)\n",
    "    \n",
    "    pair_imgs_pattern_check = pair_img1_pattern == pair_img2_pattern\n",
    "    \n",
    "    pair_overlap_ratio = pair_imgs_pattern_check.sum() / len(pair_imgs_pattern_check[0])\n",
    "    \n",
    "    avg_pair_check_ratio += pair_overlap_ratio\n",
    "\n",
    "    \n",
    "avg_pair_check_ratio = avg_pair_check_ratio / pair_num\n",
    "\n",
    "print(f\"\\nAverage pattern overlap ratio over {pair_num} random pairs {avg_pair_check_ratio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223ff090",
   "metadata": {},
   "source": [
    "## Checking the pattern overlap ratio between $\\alpha I$ and $I$, the pattern includes all the neurons\n",
    "Sample a list of $\\alpha$'s on $[0,1]$, checking the pattern overlap ratio between $\\alpha I$ and $I$, find the average $\\alpha$ for the ratio can pass some given threshold $r$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b045f7d1",
   "metadata": {},
   "source": [
    "#### threshold $r = 1$, i.e. the patterns of $\\alpha I$ and $I$ has to be exactly same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7d692d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 1\n",
      "\n",
      "alphas picked: \n",
      "[0.         0.05263158 0.10526316 0.15789474 0.21052632 0.26315789\n",
      " 0.31578947 0.36842105 0.42105263 0.47368421 0.52631579 0.57894737\n",
      " 0.63157895 0.68421053 0.73684211 0.78947368 0.84210526 0.89473684\n",
      " 0.94736842 1.        ] \n",
      "\n",
      "indices of 200 images going to be checked: \n",
      " [8970  733 6442 1234 1462 7431 8984 5069 2206 7289 6711 9318 5536 6413\n",
      " 5912 2045 4236 3238 7868 5484 6081 4401 6751 1506 4264 2052 8174 4092\n",
      "  444 7685 7726 1265 4656 9439 1731 7368 4261 2360 3407  732  308 7036\n",
      " 7806 6540 3041 5988 2097 7442 7445 3558 8155 5034 9743 1565 3267 7409\n",
      " 5573 1569  235 7028 9400 3207 6948 9250 4865 5459 2330 1072 8246 8602\n",
      " 8344 4568 9544 4172 7230 7435 3989 2711 3786 9085 6405  527 7314 2088\n",
      " 5489 4227 5413 7622 7515 1918 7938 6058 1231 7303 3069  345 1542 4968\n",
      " 9051 3368 2657 8905 2223 4144 1843 8341  188 7691 1873 9662 6949 2185\n",
      " 8090 8202 7720 3901 7793 2048  248 7395 3561 8651  286  859 5946  994\n",
      " 9681 3982  595 7787 6658 1668  644  471 6873 8379 3976  231 9702 1112\n",
      " 1933 6137 4006 5061 8579 8781  764 6675 7240  510 6940 1846 1326 9977\n",
      " 7652 2822 6957 7339 3535 2385 2468 3551 8654 8272 8301  313 4532 6252\n",
      " 3475 2196 9189 9967 2320 5328 8988 2955 2867 4041 3599 5006 7761 5280\n",
      " 6326 4439 4179 2885 1749 8458 8539 5416 6855 5773 3221 8896 6849 3358\n",
      " 7335 8846  366 2043]\n",
      "\n",
      " Avg alpha for satisfying threshold: 0.770263157894736\n"
     ]
    }
   ],
   "source": [
    "###########################Set parames###########################\n",
    "num_sample = 20 # number of alpha values to sample between [0,1]\n",
    "num_check = 200 # number of images to check\n",
    "\n",
    "thrd = 1\n",
    "print(f\"Threshold: {thrd}\\n\")\n",
    "###################################################################\n",
    "\n",
    "\n",
    "alps = np.linspace(0, 1, num_sample)\n",
    "alps = np.sort(alps) \n",
    "print(f\"alphas picked: \\n{alps} \\n\")\n",
    "\n",
    "\n",
    "img_idxes = np.random.choice(range(10000), num_check, replace=False)\n",
    "check_set = torch.utils.data.Subset(dataset2, img_idxes)\n",
    "print(f\"indices of {num_check} images going to be checked: \\n {img_idxes}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "avg_alp_satified_thrd = 0\n",
    "\n",
    "for (rdm_img, rdm_target) in check_set:\n",
    "\n",
    "    rdm_img_extend = rdm_img[None, :]\n",
    "\n",
    "    img_pattern = model.get_pattern(rdm_img_extend, layers, device, flatten=True)\n",
    "    \n",
    "    satify_thrd = False\n",
    "    for i in range(len(alps)):\n",
    "        a = alps[i]\n",
    "        if a == 0:\n",
    "            continue\n",
    "        discounted_img = a*rdm_img_extend\n",
    "\n",
    "        discounted_img_pattern = model.get_pattern(discounted_img, layers, device, flatten=True)\n",
    "        pattern_check = img_pattern == discounted_img_pattern\n",
    "        pattern_check_ratio = pattern_check.sum() / len(pattern_check[0])\n",
    "        \n",
    "        if pattern_check_ratio >= thrd and not satify_thrd:\n",
    "            avg_alp_satified_thrd += a\n",
    "            satify_thrd = True\n",
    "    \n",
    "#         print(\"pattern check ratio:\", pattern_check_ratio)\n",
    "#         print(\"number of neuron in difference:\", len(pattern_check[0])-pattern_check.sum() )\n",
    "\n",
    "avg_alp_satified_thrd = avg_alp_satified_thrd / num_check\n",
    "print(f\"\\n Avg alpha for satisfying threshold: {avg_alp_satified_thrd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d70b0f",
   "metadata": {},
   "source": [
    "## Check the range for pattern overlap ratio does not satisfy the threshold anymore\n",
    "Setting two thresholds $r_{low}$ and $r_{high}$ and find the range of the $\\alpha$'s that can still make the overlap ration between $\\alpha I$ and $I$ satisfies the threshold.\n",
    "- $r_{low}$ is for overlap ratio obtained on $\\alpha \\in [0,1]$ and $r_{high}$ is for overlap ratio obtained on $\\alpha \\in [1,\\infty]$\n",
    "- Since when $\\alpha$ moves from 0 to 1, the ratio will increase and reach 1 at $\\alpha=1$, when $\\alpha$ continues to increase, i.e. $1 \\to \\infty $, it will decrease again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d66d3e5",
   "metadata": {},
   "source": [
    "##### Observation of results from below:\n",
    "- If we set the high threshold to be anything smaller than 1 like 0.97, it will very difficult to find the breaking point alpha (it could be super large value like more than 7 digits)\n",
    "- So instead, we have the high threshold to be 1.0. We set the number of samples we check to get the average to be 100. And the result os around 1.82.\n",
    "- The low threshold, is around 0.77.\n",
    "- Since the step value is too small, we set the limitation to be 20.\n",
    "- Need to define what is considered as break?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5753fd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices of 10 images going to be checked: \n",
      " [1309 2606 8849 2251 1981 1880 2638 3670 6766 6584]\n",
      "====================\n",
      "find low: 0.7500000000000001\n",
      "====================\n",
      "find low: 0.8000000000000002\n",
      "find high: 1.06\n",
      "====================\n",
      "find low: 0.6\n",
      "find high: 1.1\n",
      "====================\n",
      "find low: 0.7500000000000001\n",
      "find high: 1.03\n",
      "====================\n",
      "find low: 0.9000000000000002\n",
      "find high: 1.1\n",
      "====================\n",
      "find low: 0.9000000000000002\n",
      "find high: 1.1600000000000001\n",
      "====================\n",
      "find low: 0.6\n",
      "find high: 2.0100000000000007\n",
      "====================\n",
      "find low: 0.5499999999999999\n",
      "find high: 1.2700000000000002\n",
      "====================\n",
      "find low: 0.7000000000000001\n",
      "====================\n",
      "find low: 0.8500000000000002\n",
      "find high: 2.0100000000000007\n",
      "Totally 2 samples cannot find the break point for high bound.\n",
      "\n",
      " Avg alpha for satisfying the low threshold: 0.7400000000000001\n",
      "\n",
      " Avg alpha for satisfying the high threshold: 1.3425000000000002\n"
     ]
    }
   ],
   "source": [
    "##########################Set params###########################\n",
    "\n",
    "# number of images to check\n",
    "num_check = 10 \n",
    "\n",
    "# setting the step of increasing the value of alpha on [0,1] and [1, infinity] respectively\n",
    "# instead of using the np.linspace() to sample the alphas, we use step here\n",
    "alps_step_low = 0.05\n",
    "alps_step_high = 0.01\n",
    "\n",
    "low_thrd = 1.0\n",
    "high_thrd = 1.0\n",
    "\n",
    "avg_alp_satified_low_thrd = 0\n",
    "avg_alp_satified_high_thrd = 0\n",
    "\n",
    "# upperbound alpha value for checking on [1, infinity], since it is possible that this checking goes infinity\n",
    "alps_upperbound = 20\n",
    "\n",
    "###############################################################\n",
    "\n",
    "# count for NOT be able to find the alpha value satisfying the threshold on [1, infinity]\n",
    "count_high_out_of_bound = 0\n",
    "\n",
    "\n",
    "img_idxes = np.random.choice(range(10000), num_check, replace=False)\n",
    "check_set = torch.utils.data.Subset(dataset2, img_idxes)\n",
    "print(f\"indices of {num_check} images going to be checked: \\n {img_idxes}\")\n",
    "\n",
    "\n",
    "\n",
    "for (rdm_img, rdm_target) in check_set:\n",
    "    print(\"====================\")\n",
    "\n",
    "    rdm_img_extend = rdm_img[None, :]\n",
    "\n",
    "    img_pattern = model.get_pattern(rdm_img_extend, layers, device, flatten=True)\n",
    "    \n",
    "    satify_low_thrd = False\n",
    "    satify_high_thrd = False\n",
    "    \n",
    "    alp = 0\n",
    "    \n",
    "    while not satify_high_thrd:\n",
    "        discounted_img = alp * rdm_img_extend\n",
    "\n",
    "        discounted_img_pattern = model.get_pattern(discounted_img, layers, device, flatten=True)\n",
    "        pattern_check = img_pattern == discounted_img_pattern\n",
    "        pattern_check_ratio = pattern_check.sum() / len(pattern_check[0])\n",
    "        \n",
    "        if alp > 1 and not satify_low_thrd:\n",
    "            print(\"PROBLEM!!!!!\", pattern_check_ratio)\n",
    "        \n",
    "        if pattern_check_ratio >= low_thrd and not satify_low_thrd:\n",
    "            avg_alp_satified_low_thrd += alp\n",
    "            satify_low_thrd = True\n",
    "            print(f\"find low: {alp}\")\n",
    "            alp = 1\n",
    "            \n",
    "        elif satify_low_thrd and not satify_high_thrd and pattern_check_ratio < high_thrd:\n",
    "            avg_alp_satified_high_thrd += alp\n",
    "            satify_high_thrd = True\n",
    "            print(f\"find high: {alp}\")\n",
    "            \n",
    "        elif satify_low_thrd and not satify_high_thrd and alp >= alps_upperbound:\n",
    "            count_high_out_of_bound += 1\n",
    "            break\n",
    "        \n",
    "#         print(\"pattern check ratio:\", pattern_check_ratio)\n",
    "#         print(\"number of neuron in difference:\", len(pattern_check[0])-pattern_check.sum() )\n",
    "            \n",
    "        if not satify_low_thrd:\n",
    "            alp += alps_step_low\n",
    "            alp = min(1, alp)\n",
    "        else:\n",
    "            alp += alps_step_high\n",
    "        \n",
    "\n",
    "avg_alp_satified_low_thrd = avg_alp_satified_low_thrd / num_check\n",
    "avg_alp_satified_high_thrd = avg_alp_satified_high_thrd / (num_check - count_high_out_of_bound) if (num_check - count_high_out_of_bound) != 0 else None \n",
    "\n",
    "print(f\"Totally {count_high_out_of_bound} samples cannot find the break point for high bound.\")\n",
    "print(f\"\\n Avg alpha for satisfying the low threshold: {avg_alp_satified_low_thrd}\")\n",
    "print(f\"\\n Avg alpha for satisfying the high threshold: {avg_alp_satified_high_thrd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9724448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
